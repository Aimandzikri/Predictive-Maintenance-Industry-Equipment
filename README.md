# Predictive Maintenance for Turbofan Engines (NASA CMAPSS FD001)

This project demonstrates an end-to-end **Remaining Useful Life (RUL)** prediction pipeline for aircraft engines using the NASA CMAPSS dataset (single-fault scenario **FD001**).

The repository is organised around three production-ready Python scripts ‚Äì **no notebooks** ‚Äì and a Streamlit dashboard for interactive exploration.

üöÄ **[Launch the App](https://predictivemaintenance-industry.streamlit.app/)**  
üì∫ **[Watch the Demo Video](https://youtu.be/j2kfLIAS0PY)**

---

## 1. Quick Start

```bash
# 1. (Optional) create & activate virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r src/requirements.txt

# 3. Pre-process data & train model (‚âà 1 minute)
python src/preprocess.py
python src/train.py

# 4. Launch the dashboard
streamlit run src/app.py
```

Open the URL printed by Streamlit to view the dashboard.

---

## 2. Repository Structure

```
Predictive Maintenance for Industrial Equipment/
‚îú‚îÄ‚îÄ data/               # Raw & processed data (git-ignored except small samples)
‚îú‚îÄ‚îÄ models/             # Saved model, scaler & metadata (after training)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py   # Data cleaning & RUL engineering
‚îÇ   ‚îú‚îÄ‚îÄ train.py        # Feature engineering & XGBoost training
‚îÇ   ‚îú‚îÄ‚îÄ app.py          # Streamlit dashboard
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## 3. Model Architecture & Training

The predictive maintenance system is powered by an **XGBoost** (eXtreme Gradient Boosting) regressor, chosen for its superior performance in handling time-series sensor data and its ability to capture complex, non-linear relationships in the data.

### Key Model Features:
- **Algorithm**: XGBoost Regressor with optimized hyperparameters
- **Input Features**: 14 sensor readings + 3 operational settings
- **Feature Engineering**:
  - Rolling window statistics (5-cycle window)
  - Mean and standard deviation calculations
  - Min-Max scaling for sensor normalization
- **Target Variable**: Remaining Useful Life (RUL) in cycles
- **Training Objective**: Minimize Root Mean Squared Error (RMSE)
- **Model Artifacts**:
  - `xgboost_model.json`: Serialized model weights
  - `scaler.pkl`: Fitted MinMaxScaler for data normalization
  - `feature_names.json`: List of feature names for inference

### Model Performance:
- **RMSE**: [Value] cycles (on test set)
- **MAE**: [Value] cycles
- **¬±30 cycles accuracy**: [Value]%

## 4. Pipeline Overview

| Step | Script | Key Actions |
|------|--------|-------------|
| 1Ô∏è‚É£ | `preprocess.py` | ‚Ä¢ Load **train_FD001.txt** / **test_FD001.txt**  \<br>‚Ä¢ Remove constant sensors  \<br>‚Ä¢ Compute & cap RUL at 125 cycles  \<br>‚Ä¢ Save `train_processed.csv`, `test_processed.csv` |
| 2Ô∏è‚É£ | `train.py` | ‚Ä¢ Feature engineering with rolling windows (mean & std, window=5)  \<br>‚Ä¢ Min-Max scaling for sensor normalization  \<br>‚Ä¢ Train **XGBoost** regressor with early stopping  \<br>‚Ä¢ Save model artifacts (`xgboost_model.json`, `scaler.pkl`, `feature_names.json`) |
| 3Ô∏è‚É£ | `app.py` | ‚Ä¢ Interactive dashboard for model inference  \<br>‚Ä¢ Performance metrics (RMSE, MAE, % within ¬±30 cycles)  \<br>‚Ä¢ Real-time RUL predictions for individual engines  \<br>‚Ä¢ Sensor trend visualization and feature importance analysis |

---

## 5. Dashboard Walk-Through

1. **Model Benchmarks** ‚Äì Quickly assess model quality on unseen engines:  
   ‚Ä¢ **RMSE** ‚Äì Typical prediction error (cycles)  
   ‚Ä¢ **Avg. Absolute Error** ‚Äì Mean absolute deviation  
   ‚Ä¢ **% within ¬±30 cycles** ‚Äì Fraction of engines where prediction is close.
2. **Choose an Engine** ‚Äì Select an engine ID (1-100).
3. **Select Current Cycle** ‚Äì Drag the slider to any historical cycle.
4. **Predicted RUL Gauge** ‚Äì Immediate visual of remaining life:  
   ‚Ä¢ Green (>100 cycles), Amber (30‚Äì100), Red (‚â§30).
5. **True RUL & Error** ‚Äì Ground-truth comparison for trust.
6. **Sensor Trends** ‚Äì Line chart of key sensors over time with the current cycle highlighted.
7. **Feature Importance** ‚Äì Top model drivers for transparency.

> **Tip:** Use the expander below the benchmarks for a plain-English explanation of each metric.

---

## 6. Model Explainability & Interpretability

The model's predictions are made interpretable through:
- **Feature Importance**: Visualizing which sensor readings most influence predictions
- **SHAP Values**: Explaining individual predictions by showing the contribution of each feature
- **Trend Analysis**: Highlighting how sensor behavior evolves as the engine approaches failure

## 7. Model Deployment & Inference

The trained model can be easily integrated into production systems through:
- **REST API** (Flask/FastAPI wrapper)
- **Batch Processing** for offline predictions
- **Real-time Monitoring** for live equipment tracking

---

## 8. Dataset

NASA Turbofan Engine Degradation Simulation (CMAPSS) ‚Äì subset **FD001** (single operating condition, single fault). Original data available at the [PHM Society Data Challenge](https://www.phmsociety.org/).

---

## 9. Requirements

Python ‚â•3.9. All Python package versions are pinned in `src/requirements.txt`.

---
